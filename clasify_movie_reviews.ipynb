{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/delqn/tf_classify_text/blob/master/clasify_movie_reviews.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "GzbzVSgE3KYA",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503.0
    },
    "outputId": "ad66c511-8a92-4232-80fa-6400e3752a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n",
      "Loading dataset from ./aclImdb_v1.tar.gz\n",
      "Loaded dataset -> <type 'str'>: /content/.keras/datasets/aclImdb.tar.gz\n",
      "Training set accuracy: 0.501720011234\n",
      "Test set accuracy: 0.497519999743\n",
      "Test set accuracy: 0.5\n",
      "loss\n",
      "accuracy_baseline\n",
      "global_step\n",
      "recall\n",
      "auc\n",
      "prediction/mean\n",
      "precision\n",
      "label/mean\n",
      "average_loss\n",
      "auc_precision_recall\n",
      "accuracy\n",
      "('bad', (10, 'This was an amazing film'))\n",
      "('good', (1, 'This movie is terrible'))\n",
      "('bad', (9, 'Absolutely great'))\n",
      "('bad', (9, 'Great film. I enjoyed and highly recommend it.'))\n",
      "('bad', (0, 'Singing in the rain is a fabulously entertaining musical.'))\n",
      "('bad', (0, 'Marchella is an awful example of humanity at its worst.'))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running w/ module https://tfhub.dev/google/nnlm-en-dim128/1; trained=False\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2.7\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "# Load all files from a directory in a DataFrame.\n",
    "def load_as_dataframe(directory):\n",
    "  data = {\n",
    "      'sentence': [],\n",
    "      'sentiment': [],\n",
    "  }\n",
    "  for file_path in os.listdir(directory):\n",
    "    with tf.gfile.GFile(os.path.join(directory, file_path), 'r') as f:\n",
    "      data['sentence'].append(f.read())\n",
    "      data['sentiment'].append(re.match('\\d+_(\\d+)\\.txt', file_path).group(1))\n",
    "  return pd.DataFrame.from_dict(data)\n",
    "\n",
    "\n",
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset(directory):\n",
    "  pos_df = load_as_dataframe(os.path.join(directory, 'pos'))\n",
    "  neg_df = load_as_dataframe(os.path.join(directory, 'neg'))\n",
    "  pos_df['polarity'] = 1\n",
    "  neg_df['polarity'] = 0\n",
    "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def download_and_load_datasets(force_download=False):\n",
    "    \"\"\"Download and process the dataset files.\"\"\"\n",
    "    origin = './aclImdb_v1.tar.gz'\n",
    "    if force_download:\n",
    "        origin = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "    print('Loading dataset from {}'.format(origin))\n",
    "    dataset = tf.keras.utils.get_file(fname='aclImdb.tar.gz', origin=origin, extract=True)\n",
    "    print('Loaded dataset -> {}: {}'.format(type(dataset), dataset))\n",
    "    return (\n",
    "        load_dataset(os.path.join(os.path.dirname(dataset), 'aclImdb', 'train')),\n",
    "        load_dataset(os.path.join(os.path.dirname(dataset), 'aclImdb', 'test')))\n",
    "\n",
    "\n",
    "def train():\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)  # NOTE: INFO is too verbose\n",
    "    train_df, test_df = download_and_load_datasets()\n",
    "    train_df.head()\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def get_estimator(train_df, test_df):\n",
    "    \"\"\"Training input on the whole training set with no limit on training epochs.\"\"\"\n",
    "    train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "        train_df, train_df['polarity'], num_epochs=None, shuffle=True)\n",
    "\n",
    "    # Prediction on the whole training set.\n",
    "    predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "        train_df, train_df['polarity'], shuffle=False)\n",
    "    # Prediction on the test set.\n",
    "    predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "        test_df, test_df['polarity'], shuffle=False)\n",
    "\n",
    "    # Feature columns: TF-Hub provides a feature column that applies a module on the\n",
    "    # given text feature and passes further the outputs of the module.\n",
    "    embedded_text_feature_column = hub.text_embedding_column(\n",
    "        key=\"sentence\",\n",
    "        module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
    "\n",
    "    # Estimator: for classification we can use a DNN Classifier\n",
    "    estimator = tf.estimator.DNNClassifier(\n",
    "        hidden_units=[500, 100],\n",
    "        feature_columns=[embedded_text_feature_column],\n",
    "        n_classes=2,\n",
    "        optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n",
    "\n",
    "    train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
    "    test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "\n",
    "    print \"Training set accuracy: {accuracy}\".format(**train_eval_result)\n",
    "    print \"Test set accuracy: {accuracy}\".format(**test_eval_result)\n",
    "    return estimator\n",
    "\n",
    "  \n",
    "def hacked_out_2(estimator__):\n",
    "    sentences = [\n",
    "        'This was an amazing film',\n",
    "        'This movie is terrible',\n",
    "        'Absolutely great',\n",
    "        'Great film. I enjoyed and highly recommend it.',\n",
    "        'Singing in the rain is a fabulously entertaining musical.',\n",
    "        'Marchella is an awful example of humanity at its worst.'\n",
    "    ]\n",
    "    sentiment = [10, 1, 9, 9, 0, 0]\n",
    "    polarity = [1,0,1,1, 0, 0]\n",
    "    data = {'sentence': sentences, 'sentiment': sentiment, 'polarity': polarity}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # df = train_df\n",
    "\n",
    "    ########\n",
    "\n",
    "    sentences_movies = list(zip(df['sentiment'].tolist()[:15], df['sentence'].tolist()[:15]))\n",
    "\n",
    "\n",
    "    input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "        df,\n",
    "        df[\"polarity\"],\n",
    "        shuffle=False)\n",
    "\n",
    "    estimates = estimator__.evaluate(input_fn=input_fn)\n",
    "    print(\"Test set accuracy: {accuracy}\".format(**estimates))\n",
    "    for est in estimates:\n",
    "      print(est)\n",
    "\n",
    "    def get_predictions(estimatorx, input_fn):\n",
    "      return [x[\"class_ids\"][0] for x in estimatorx.predict(input_fn=input_fn)]\n",
    "\n",
    "    predictions = estimator__.predict(input_fn=input_fn)\n",
    "    ## print(df)\n",
    "    # for idx, p in enumerate(predictions):\n",
    "    #  print(p['logits'][0], p['probabilities'], p['classes'], p['classes'] == b'0', sentences_movies[idx])\n",
    "\n",
    "    def print_res(estimator_):\n",
    "        for idx, p in enumerate(get_predictions(estimator_, input_fn)):\n",
    "            print('good' if p else 'bad', sentences_movies[idx])\n",
    "        print('\\n' * 3)\n",
    "\n",
    "    print_res(estimator__)\n",
    "\n",
    "    def train_and_evaluate_with_module(hub_module, train_module=False):\n",
    "      embedded_text_feature_column = hub.text_embedding_column(\n",
    "          key=\"sentence\", module_spec=hub_module, trainable=train_module)\n",
    "\n",
    "      estimator = tf.estimator.DNNClassifier(\n",
    "          hidden_units=[500, 100],\n",
    "          feature_columns=[embedded_text_feature_column],\n",
    "          n_classes=2,\n",
    "          optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n",
    "\n",
    "      estimator.train(input_fn=input_fn, steps=1000)\n",
    "      return estimator\n",
    "    \n",
    "    tf_modules = [\n",
    "        (\"https://tfhub.dev/google/nnlm-en-dim128/1\", False),\n",
    "        (\"https://tfhub.dev/google/nnlm-en-dim128/1\", True),\n",
    "        (\"https://tfhub.dev/google/random-nnlm-en-dim128/1\", False),\n",
    "        (\"https://tfhub.dev/google/random-nnlm-en-dim128/1\", True),\n",
    "    ]\n",
    "    for tfhub_module, train in tf_modules:\n",
    "        print('Running w/ module {}; trained={}'.format(tfhub_module, train))\n",
    "        print_res(train_and_evaluate_with_module(tfhub_module, train))\n",
    "        print('\\n' * 3)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    hacked_out_2(get_estimator(*train()))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "clasify_movie_reviews.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python2",
   "display_name": "Python 2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
